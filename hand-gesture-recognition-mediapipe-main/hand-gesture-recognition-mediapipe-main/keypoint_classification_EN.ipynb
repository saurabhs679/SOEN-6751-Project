{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = 'C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = 'C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint_classifier.hdf5'\n",
        "tflite_save_path = 'C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_6 (Dropout)         (None, 42)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 20)                860       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1125 (4.39 KB)\n",
            "Trainable params: 1125 (4.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/31 [..............................] - ETA: 7s - loss: 1.6089 - accuracy: 0.2188\n",
            "Epoch 1: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 1.5305 - accuracy: 0.2998 - val_loss: 1.4313 - val_accuracy: 0.3634\n",
            "Epoch 2/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.4836 - accuracy: 0.3281\n",
            "Epoch 2: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.3415 - val_loss: 1.3314 - val_accuracy: 0.3927\n",
            "Epoch 3/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.3478 - accuracy: 0.3516\n",
            "Epoch 3: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.3682 - accuracy: 0.3590 - val_loss: 1.2798 - val_accuracy: 0.4298\n",
            "Epoch 4/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.3088 - accuracy: 0.3672\n",
            "Epoch 4: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 0s 2ms/step - loss: 1.3301 - accuracy: 0.3747 - val_loss: 1.2385 - val_accuracy: 0.4414\n",
            "Epoch 5/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.2653 - accuracy: 0.4375\n",
            "Epoch 5: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.3028 - accuracy: 0.3873 - val_loss: 1.1990 - val_accuracy: 0.4985\n",
            "Epoch 6/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.3112 - accuracy: 0.3672\n",
            "Epoch 6: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.2798 - accuracy: 0.3971 - val_loss: 1.1601 - val_accuracy: 0.5015\n",
            "Epoch 7/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.2902 - accuracy: 0.3203\n",
            "Epoch 7: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.2447 - accuracy: 0.4207 - val_loss: 1.1202 - val_accuracy: 0.5309\n",
            "Epoch 8/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.2110 - accuracy: 0.4766\n",
            "Epoch 8: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.2064 - accuracy: 0.4457 - val_loss: 1.0729 - val_accuracy: 0.5532\n",
            "Epoch 9/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.2901 - accuracy: 0.4375\n",
            "Epoch 9: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.1798 - accuracy: 0.4678 - val_loss: 1.0209 - val_accuracy: 0.6319\n",
            "Epoch 10/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.2200 - accuracy: 0.4609\n",
            "Epoch 10: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.1457 - accuracy: 0.4959 - val_loss: 0.9692 - val_accuracy: 0.6644\n",
            "Epoch 11/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.0750 - accuracy: 0.5312\n",
            "Epoch 11: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.1117 - accuracy: 0.5188 - val_loss: 0.9218 - val_accuracy: 0.6836\n",
            "Epoch 12/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.1704 - accuracy: 0.5000\n",
            "Epoch 12: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.0897 - accuracy: 0.5106 - val_loss: 0.8831 - val_accuracy: 0.7130\n",
            "Epoch 13/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.1849 - accuracy: 0.4844\n",
            "Epoch 13: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.0680 - accuracy: 0.5407 - val_loss: 0.8409 - val_accuracy: 0.7346\n",
            "Epoch 14/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.9014 - accuracy: 0.6328\n",
            "Epoch 14: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.0385 - accuracy: 0.5450 - val_loss: 0.8006 - val_accuracy: 0.7670\n",
            "Epoch 15/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.0577 - accuracy: 0.5312\n",
            "Epoch 15: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.0215 - accuracy: 0.5512 - val_loss: 0.7663 - val_accuracy: 0.7770\n",
            "Epoch 16/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.9905 - accuracy: 0.5312\n",
            "Epoch 16: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.0042 - accuracy: 0.5726 - val_loss: 0.7305 - val_accuracy: 0.7986\n",
            "Epoch 17/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.9224 - accuracy: 0.6016\n",
            "Epoch 17: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.9841 - accuracy: 0.5751 - val_loss: 0.6934 - val_accuracy: 0.7978\n",
            "Epoch 18/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.9304 - accuracy: 0.6719\n",
            "Epoch 18: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.9616 - accuracy: 0.5813 - val_loss: 0.6717 - val_accuracy: 0.8164\n",
            "Epoch 19/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.9022 - accuracy: 0.6328\n",
            "Epoch 19: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.9306 - accuracy: 0.6040 - val_loss: 0.6405 - val_accuracy: 0.8719\n",
            "Epoch 20/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.9351 - accuracy: 0.6250\n",
            "Epoch 20: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.9254 - accuracy: 0.6081 - val_loss: 0.6158 - val_accuracy: 0.8812\n",
            "Epoch 21/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.9647 - accuracy: 0.6016\n",
            "Epoch 21: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.6171 - val_loss: 0.5953 - val_accuracy: 0.8881\n",
            "Epoch 22/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8970 - accuracy: 0.6250\n",
            "Epoch 22: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8930 - accuracy: 0.6310 - val_loss: 0.5715 - val_accuracy: 0.8904\n",
            "Epoch 23/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 1.0060 - accuracy: 0.5781\n",
            "Epoch 23: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8912 - accuracy: 0.6372 - val_loss: 0.5506 - val_accuracy: 0.8966\n",
            "Epoch 24/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8967 - accuracy: 0.6641\n",
            "Epoch 24: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8810 - accuracy: 0.6400 - val_loss: 0.5379 - val_accuracy: 0.9082\n",
            "Epoch 25/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8538 - accuracy: 0.6406\n",
            "Epoch 25: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8591 - accuracy: 0.6516 - val_loss: 0.5161 - val_accuracy: 0.9082\n",
            "Epoch 26/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8352 - accuracy: 0.6641\n",
            "Epoch 26: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8358 - accuracy: 0.6585 - val_loss: 0.4949 - val_accuracy: 0.9113\n",
            "Epoch 27/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8076 - accuracy: 0.6719\n",
            "Epoch 27: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8505 - accuracy: 0.6467 - val_loss: 0.4832 - val_accuracy: 0.9136\n",
            "Epoch 28/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7094 - accuracy: 0.7188\n",
            "Epoch 28: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7881 - accuracy: 0.6783 - val_loss: 0.4642 - val_accuracy: 0.9120\n",
            "Epoch 29/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8622 - accuracy: 0.6250\n",
            "Epoch 29: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8239 - accuracy: 0.6701 - val_loss: 0.4598 - val_accuracy: 0.9120\n",
            "Epoch 30/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7213 - accuracy: 0.7422\n",
            "Epoch 30: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7902 - accuracy: 0.6899 - val_loss: 0.4453 - val_accuracy: 0.9205\n",
            "Epoch 31/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7339 - accuracy: 0.6953\n",
            "Epoch 31: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.6891 - val_loss: 0.4338 - val_accuracy: 0.9174\n",
            "Epoch 32/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7222 - accuracy: 0.7344\n",
            "Epoch 32: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7801 - accuracy: 0.6909 - val_loss: 0.4218 - val_accuracy: 0.9252\n",
            "Epoch 33/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8033 - accuracy: 0.6953\n",
            "Epoch 33: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7701 - accuracy: 0.6945 - val_loss: 0.4144 - val_accuracy: 0.9244\n",
            "Epoch 34/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7648 - accuracy: 0.7266\n",
            "Epoch 34: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7623 - accuracy: 0.6966 - val_loss: 0.4062 - val_accuracy: 0.9228\n",
            "Epoch 35/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7286 - accuracy: 0.7031\n",
            "Epoch 35: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7618 - accuracy: 0.6999 - val_loss: 0.4002 - val_accuracy: 0.9252\n",
            "Epoch 36/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6914 - accuracy: 0.7188\n",
            "Epoch 36: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7015 - val_loss: 0.3914 - val_accuracy: 0.9282\n",
            "Epoch 37/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6874 - accuracy: 0.7578\n",
            "Epoch 37: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7601 - accuracy: 0.7046 - val_loss: 0.3921 - val_accuracy: 0.9267\n",
            "Epoch 38/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7285 - accuracy: 0.6641\n",
            "Epoch 38: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7357 - accuracy: 0.7043 - val_loss: 0.3875 - val_accuracy: 0.9259\n",
            "Epoch 39/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6908 - accuracy: 0.7344\n",
            "Epoch 39: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7367 - accuracy: 0.7015 - val_loss: 0.3848 - val_accuracy: 0.9298\n",
            "Epoch 40/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6748 - accuracy: 0.7266\n",
            "Epoch 40: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7434 - accuracy: 0.7046 - val_loss: 0.3781 - val_accuracy: 0.9321\n",
            "Epoch 41/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8085 - accuracy: 0.6797\n",
            "Epoch 41: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7171 - accuracy: 0.7110 - val_loss: 0.3705 - val_accuracy: 0.9336\n",
            "Epoch 42/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.8214 - accuracy: 0.6094\n",
            "Epoch 42: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.7120 - val_loss: 0.3672 - val_accuracy: 0.9329\n",
            "Epoch 43/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7492 - accuracy: 0.6953\n",
            "Epoch 43: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.7231 - val_loss: 0.3597 - val_accuracy: 0.9298\n",
            "Epoch 44/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6592 - accuracy: 0.7422\n",
            "Epoch 44: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.7293 - val_loss: 0.3559 - val_accuracy: 0.9290\n",
            "Epoch 45/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6871 - accuracy: 0.7031\n",
            "Epoch 45: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.7241 - val_loss: 0.3552 - val_accuracy: 0.9282\n",
            "Epoch 46/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6591 - accuracy: 0.7656\n",
            "Epoch 46: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.7231 - val_loss: 0.3536 - val_accuracy: 0.9313\n",
            "Epoch 47/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6473 - accuracy: 0.7422\n",
            "Epoch 47: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.7290 - val_loss: 0.3422 - val_accuracy: 0.9336\n",
            "Epoch 48/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6871 - accuracy: 0.7031\n",
            "Epoch 48: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.7280 - val_loss: 0.3465 - val_accuracy: 0.9352\n",
            "Epoch 49/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6848 - accuracy: 0.7109\n",
            "Epoch 49: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.7424 - val_loss: 0.3390 - val_accuracy: 0.9329\n",
            "Epoch 50/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7121 - accuracy: 0.6719\n",
            "Epoch 50: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.7450 - val_loss: 0.3275 - val_accuracy: 0.9344\n",
            "Epoch 51/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6489 - accuracy: 0.7109\n",
            "Epoch 51: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7324 - val_loss: 0.3286 - val_accuracy: 0.9313\n",
            "Epoch 52/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6201 - accuracy: 0.7891\n",
            "Epoch 52: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.7283 - val_loss: 0.3387 - val_accuracy: 0.9321\n",
            "Epoch 53/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6579 - accuracy: 0.7578\n",
            "Epoch 53: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.7414 - val_loss: 0.3299 - val_accuracy: 0.9360\n",
            "Epoch 54/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6568 - accuracy: 0.7344\n",
            "Epoch 54: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.7259 - val_loss: 0.3341 - val_accuracy: 0.9344\n",
            "Epoch 55/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6351 - accuracy: 0.7812\n",
            "Epoch 55: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.7283 - val_loss: 0.3349 - val_accuracy: 0.9313\n",
            "Epoch 56/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7109\n",
            "Epoch 56: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.7434 - val_loss: 0.3274 - val_accuracy: 0.9336\n",
            "Epoch 57/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6012 - accuracy: 0.7969\n",
            "Epoch 57: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.7355 - val_loss: 0.3269 - val_accuracy: 0.9275\n",
            "Epoch 58/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6433 - accuracy: 0.7188\n",
            "Epoch 58: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.7491 - val_loss: 0.3258 - val_accuracy: 0.9290\n",
            "Epoch 59/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6078 - accuracy: 0.7891\n",
            "Epoch 59: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.7427 - val_loss: 0.3201 - val_accuracy: 0.9336\n",
            "Epoch 60/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7350 - accuracy: 0.7031\n",
            "Epoch 60: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.7414 - val_loss: 0.3220 - val_accuracy: 0.9336\n",
            "Epoch 61/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5349 - accuracy: 0.8281\n",
            "Epoch 61: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.7504 - val_loss: 0.3163 - val_accuracy: 0.9352\n",
            "Epoch 62/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5930 - accuracy: 0.7578\n",
            "Epoch 62: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.7470 - val_loss: 0.3212 - val_accuracy: 0.9329\n",
            "Epoch 63/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6675 - accuracy: 0.7344\n",
            "Epoch 63: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7532 - val_loss: 0.3164 - val_accuracy: 0.9360\n",
            "Epoch 64/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6555 - accuracy: 0.7656\n",
            "Epoch 64: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7447 - val_loss: 0.3116 - val_accuracy: 0.9321\n",
            "Epoch 65/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6643 - accuracy: 0.7109\n",
            "Epoch 65: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.7470 - val_loss: 0.3122 - val_accuracy: 0.9306\n",
            "Epoch 66/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5720 - accuracy: 0.7656\n",
            "Epoch 66: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7470 - val_loss: 0.3126 - val_accuracy: 0.9282\n",
            "Epoch 67/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.4379 - accuracy: 0.8516\n",
            "Epoch 67: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7661 - val_loss: 0.3014 - val_accuracy: 0.9306\n",
            "Epoch 68/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5860 - accuracy: 0.7656\n",
            "Epoch 68: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7537 - val_loss: 0.3071 - val_accuracy: 0.9336\n",
            "Epoch 69/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5338 - accuracy: 0.8047\n",
            "Epoch 69: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.7712 - val_loss: 0.3049 - val_accuracy: 0.9313\n",
            "Epoch 70/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6458 - accuracy: 0.7812\n",
            "Epoch 70: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.7537 - val_loss: 0.3014 - val_accuracy: 0.9313\n",
            "Epoch 71/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7303 - accuracy: 0.7266\n",
            "Epoch 71: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.7612 - val_loss: 0.3029 - val_accuracy: 0.9336\n",
            "Epoch 72/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5144 - accuracy: 0.8125\n",
            "Epoch 72: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.7537 - val_loss: 0.3050 - val_accuracy: 0.9344\n",
            "Epoch 73/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6089 - accuracy: 0.7578\n",
            "Epoch 73: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.7581 - val_loss: 0.2977 - val_accuracy: 0.9344\n",
            "Epoch 74/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6529 - accuracy: 0.7188\n",
            "Epoch 74: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.7483 - val_loss: 0.3025 - val_accuracy: 0.9313\n",
            "Epoch 75/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5871 - accuracy: 0.7656\n",
            "Epoch 75: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.7633 - val_loss: 0.3034 - val_accuracy: 0.9360\n",
            "Epoch 76/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5830 - accuracy: 0.7891\n",
            "Epoch 76: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.7566 - val_loss: 0.2931 - val_accuracy: 0.9398\n",
            "Epoch 77/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5394 - accuracy: 0.8125\n",
            "Epoch 77: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.7635 - val_loss: 0.2988 - val_accuracy: 0.9298\n",
            "Epoch 78/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6872 - accuracy: 0.6953\n",
            "Epoch 78: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.7571 - val_loss: 0.2970 - val_accuracy: 0.9360\n",
            "Epoch 79/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6481 - accuracy: 0.7500\n",
            "Epoch 79: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.7615 - val_loss: 0.3023 - val_accuracy: 0.9360\n",
            "Epoch 80/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6519 - accuracy: 0.7344\n",
            "Epoch 80: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7571 - val_loss: 0.2930 - val_accuracy: 0.9367\n",
            "Epoch 81/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5901 - accuracy: 0.7344\n",
            "Epoch 81: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.7687 - val_loss: 0.2961 - val_accuracy: 0.9259\n",
            "Epoch 82/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5371 - accuracy: 0.7969\n",
            "Epoch 82: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7694 - val_loss: 0.2933 - val_accuracy: 0.9344\n",
            "Epoch 83/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6552 - accuracy: 0.7891\n",
            "Epoch 83: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7669 - val_loss: 0.2929 - val_accuracy: 0.9298\n",
            "Epoch 84/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6536 - accuracy: 0.7422\n",
            "Epoch 84: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.7630 - val_loss: 0.2925 - val_accuracy: 0.9336\n",
            "Epoch 85/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6897 - accuracy: 0.7266\n",
            "Epoch 85: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.7756 - val_loss: 0.2891 - val_accuracy: 0.9429\n",
            "Epoch 86/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5613 - accuracy: 0.7891\n",
            "Epoch 86: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.7645 - val_loss: 0.2889 - val_accuracy: 0.9344\n",
            "Epoch 87/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5722 - accuracy: 0.7891\n",
            "Epoch 87: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7753 - val_loss: 0.2916 - val_accuracy: 0.9336\n",
            "Epoch 88/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6262 - accuracy: 0.7734\n",
            "Epoch 88: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.7800 - val_loss: 0.2957 - val_accuracy: 0.9352\n",
            "Epoch 89/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.7061 - accuracy: 0.7578\n",
            "Epoch 89: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.7643 - val_loss: 0.2881 - val_accuracy: 0.9421\n",
            "Epoch 90/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5490 - accuracy: 0.7812\n",
            "Epoch 90: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.7692 - val_loss: 0.2937 - val_accuracy: 0.9414\n",
            "Epoch 91/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6891 - accuracy: 0.6875\n",
            "Epoch 91: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7707 - val_loss: 0.2882 - val_accuracy: 0.9306\n",
            "Epoch 92/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5990 - accuracy: 0.7500\n",
            "Epoch 92: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.7687 - val_loss: 0.2882 - val_accuracy: 0.9275\n",
            "Epoch 93/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5861 - accuracy: 0.8047\n",
            "Epoch 93: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7730 - val_loss: 0.2869 - val_accuracy: 0.9329\n",
            "Epoch 94/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5059 - accuracy: 0.8594\n",
            "Epoch 94: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.7769 - val_loss: 0.2863 - val_accuracy: 0.9367\n",
            "Epoch 95/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5546 - accuracy: 0.7422\n",
            "Epoch 95: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.7669 - val_loss: 0.2819 - val_accuracy: 0.9275\n",
            "Epoch 96/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5522 - accuracy: 0.7656\n",
            "Epoch 96: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7710 - val_loss: 0.2921 - val_accuracy: 0.9336\n",
            "Epoch 97/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5880 - accuracy: 0.7500\n",
            "Epoch 97: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.7771 - val_loss: 0.2876 - val_accuracy: 0.9406\n",
            "Epoch 98/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6626 - accuracy: 0.7422\n",
            "Epoch 98: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7856 - val_loss: 0.2861 - val_accuracy: 0.9360\n",
            "Epoch 99/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6685 - accuracy: 0.7422\n",
            "Epoch 99: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7771 - val_loss: 0.2812 - val_accuracy: 0.9375\n",
            "Epoch 100/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.4824 - accuracy: 0.8125\n",
            "Epoch 100: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7764 - val_loss: 0.2782 - val_accuracy: 0.9398\n",
            "Epoch 101/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6234 - accuracy: 0.7188\n",
            "Epoch 101: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7784 - val_loss: 0.2802 - val_accuracy: 0.9352\n",
            "Epoch 102/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6063 - accuracy: 0.7734\n",
            "Epoch 102: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.7710 - val_loss: 0.2836 - val_accuracy: 0.9414\n",
            "Epoch 103/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5594 - accuracy: 0.7812\n",
            "Epoch 103: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.7597 - val_loss: 0.2882 - val_accuracy: 0.9383\n",
            "Epoch 104/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6802 - accuracy: 0.7500\n",
            "Epoch 104: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7784 - val_loss: 0.2911 - val_accuracy: 0.9367\n",
            "Epoch 105/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6666 - accuracy: 0.7734\n",
            "Epoch 105: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7723 - val_loss: 0.2765 - val_accuracy: 0.9367\n",
            "Epoch 106/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5716 - accuracy: 0.7969\n",
            "Epoch 106: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7805 - val_loss: 0.2830 - val_accuracy: 0.9329\n",
            "Epoch 107/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5532 - accuracy: 0.8594\n",
            "Epoch 107: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7782 - val_loss: 0.2804 - val_accuracy: 0.9398\n",
            "Epoch 108/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5533 - accuracy: 0.7969\n",
            "Epoch 108: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7838 - val_loss: 0.2686 - val_accuracy: 0.9452\n",
            "Epoch 109/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5153 - accuracy: 0.8359\n",
            "Epoch 109: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7836 - val_loss: 0.2825 - val_accuracy: 0.9429\n",
            "Epoch 110/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5480 - accuracy: 0.8125\n",
            "Epoch 110: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7867 - val_loss: 0.2777 - val_accuracy: 0.9383\n",
            "Epoch 111/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.4872 - accuracy: 0.8125\n",
            "Epoch 111: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.7692 - val_loss: 0.2852 - val_accuracy: 0.9360\n",
            "Epoch 112/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5180 - accuracy: 0.8047\n",
            "Epoch 112: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7712 - val_loss: 0.2891 - val_accuracy: 0.9375\n",
            "Epoch 113/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5018 - accuracy: 0.7500\n",
            "Epoch 113: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7735 - val_loss: 0.2845 - val_accuracy: 0.9313\n",
            "Epoch 114/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5892 - accuracy: 0.7812\n",
            "Epoch 114: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7820 - val_loss: 0.2813 - val_accuracy: 0.9313\n",
            "Epoch 115/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5517 - accuracy: 0.8125\n",
            "Epoch 115: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.7710 - val_loss: 0.2789 - val_accuracy: 0.9336\n",
            "Epoch 116/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5017 - accuracy: 0.7812\n",
            "Epoch 116: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7895 - val_loss: 0.2830 - val_accuracy: 0.9367\n",
            "Epoch 117/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5993 - accuracy: 0.7812\n",
            "Epoch 117: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7826 - val_loss: 0.2811 - val_accuracy: 0.9344\n",
            "Epoch 118/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5684 - accuracy: 0.7734\n",
            "Epoch 118: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7784 - val_loss: 0.2858 - val_accuracy: 0.9290\n",
            "Epoch 119/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.3729 - accuracy: 0.8906\n",
            "Epoch 119: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7818 - val_loss: 0.2792 - val_accuracy: 0.9367\n",
            "Epoch 120/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5010 - accuracy: 0.8125\n",
            "Epoch 120: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7864 - val_loss: 0.2772 - val_accuracy: 0.9360\n",
            "Epoch 121/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5332 - accuracy: 0.8203\n",
            "Epoch 121: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7756 - val_loss: 0.2800 - val_accuracy: 0.9329\n",
            "Epoch 122/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5544 - accuracy: 0.7734\n",
            "Epoch 122: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7759 - val_loss: 0.2724 - val_accuracy: 0.9406\n",
            "Epoch 123/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6516 - accuracy: 0.7422\n",
            "Epoch 123: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7784 - val_loss: 0.2780 - val_accuracy: 0.9290\n",
            "Epoch 124/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.4851 - accuracy: 0.8125\n",
            "Epoch 124: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7854 - val_loss: 0.2769 - val_accuracy: 0.9360\n",
            "Epoch 125/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5135 - accuracy: 0.7969\n",
            "Epoch 125: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7849 - val_loss: 0.2768 - val_accuracy: 0.9275\n",
            "Epoch 126/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.6154 - accuracy: 0.7734\n",
            "Epoch 126: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7826 - val_loss: 0.2732 - val_accuracy: 0.9390\n",
            "Epoch 127/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.5888 - accuracy: 0.7500\n",
            "Epoch 127: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7779 - val_loss: 0.2695 - val_accuracy: 0.9437\n",
            "Epoch 128/1000\n",
            " 1/31 [..............................] - ETA: 0s - loss: 0.4705 - accuracy: 0.8359\n",
            "Epoch 128: saving model to C:/Users/rohan/Downloads/hand-gesture-recognition-mediapipe-main/hand-gesture-recognition-mediapipe-main/model/keypoint_classifier\\keypoint_classifier.hdf5\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7777 - val_loss: 0.2719 - val_accuracy: 0.9468\n",
            "Epoch 128: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x20cab70c160>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3167 - accuracy: 0.9062"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 900us/step - loss: 0.2719 - accuracy: 0.9468\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "[3.1207874e-01 2.8958928e-02 7.4779950e-05 6.5888751e-01 7.1234854e-12]\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 525us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       405\n",
            "           1       0.96      0.93      0.95       373\n",
            "           2       0.94      0.97      0.95       338\n",
            "           3       1.00      0.93      0.96        81\n",
            "           4       0.93      0.82      0.87        99\n",
            "\n",
            "    accuracy                           0.95      1296\n",
            "   macro avg       0.95      0.92      0.94      1296\n",
            "weighted avg       0.95      0.95      0.95      1296\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\rohan\\AppData\\Local\\Temp\\tmp_yaoqdmg\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\rohan\\AppData\\Local\\Temp\\tmp_yaoqdmg\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6640"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.1207865e-01 2.8958930e-02 7.4779957e-05 6.5888762e-01 7.1234876e-12]\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
